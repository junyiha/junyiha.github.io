<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"junyiha.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="摘要 剪枝，蒸馏，量化">
<meta property="og:type" content="article">
<meta property="og:title" content="剪枝，蒸馏，量化">
<meta property="og:url" content="https://junyiha.github.io/2025/06/04/notebook/DeepLearning/2025-06-04--%E5%89%AA%E6%9E%9D%E8%92%B8%E9%A6%8F%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%8A%A0%E9%80%9F%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8A%80%E6%9C%AF/index.html">
<meta property="og:site_name" content="junyi&#39;s blog">
<meta property="og:description" content="摘要 剪枝，蒸馏，量化">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-04T01:00:00.000Z">
<meta property="article:modified_time" content="2025-06-04T01:07:14.252Z">
<meta property="article:author" content="zhang junyi">
<meta property="article:tag" content="AI部署">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://junyiha.github.io/2025/06/04/notebook/DeepLearning/2025-06-04--%E5%89%AA%E6%9E%9D%E8%92%B8%E9%A6%8F%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%8A%A0%E9%80%9F%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8A%80%E6%9C%AF/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>剪枝，蒸馏，量化 | junyi's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">junyi's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">hahahahaha</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://junyiha.github.io/2025/06/04/notebook/DeepLearning/2025-06-04--%E5%89%AA%E6%9E%9D%E8%92%B8%E9%A6%8F%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%8A%A0%E9%80%9F%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhang junyi">
      <meta itemprop="description" content="工作学习笔记">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="junyi's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          剪枝，蒸馏，量化
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-06-04 09:00:00 / Modified: 09:07:14" itemprop="dateCreated datePublished" datetime="2025-06-04T09:00:00+08:00">2025-06-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li>剪枝，蒸馏，量化</li>
</ul>
<span id="more"></span>

<p>下面从“剪枝（Pruning）”、“知识蒸馏（Distillation）”和“模型部署与加速”三个部分进行归纳，介绍常见的思路、方法和实践要点。这些技术往往会互相配合使用，以在保证精度的前提下，实现模型轻量化、推理加速和高效部署。</p>
<hr>
<h2 id="一、剪枝（Pruning）"><a href="#一、剪枝（Pruning）" class="headerlink" title="一、剪枝（Pruning）"></a>一、剪枝（Pruning）</h2><h3 id="1-1-剪枝的基本概念"><a href="#1-1-剪枝的基本概念" class="headerlink" title="1.1 剪枝的基本概念"></a>1.1 剪枝的基本概念</h3><ul>
<li><p><strong>目的</strong>：通过删除网络中不重要的参数或结构，使模型在保证精度下降可控的前提下，减少参数量、计算量和内存占用，从而加速推理和减小部署成本。</p>
</li>
<li><p><strong>分类</strong>：</p>
<ol>
<li><p><strong>非结构化剪枝（Unstructured Pruning）</strong></p>
<ul>
<li>直接对权重矩阵中的“个别”连接（weight）进行零化。</li>
<li>优点：可以获得较高的参数稀疏度，压缩率高。</li>
<li>缺点：稀疏程度高时，普通硬件（如 GPU、CPU）的并行加速效果有限，需要借助稀疏计算库或硬件（如 NVIDIA Sparse Tensor Cores、XNNPACK、Intel MKL Sparse）才能充分加速。</li>
</ul>
</li>
<li><p><strong>结构化剪枝（Structured Pruning）</strong></p>
<ul>
<li>按照某种粒度剪掉整个通道（channel）、整个卷积核（kernel）、整个注意力头（head），或者整个网络层。</li>
<li>优点：剪掉之后的网络仍然保持规则张量形状，兼容主流深度学习加速库（cuDNN、TensorRT、OpenVINO 等），易于获得明显的加速。</li>
<li>缺点：相对于非结构化剪枝同等精度损失下，压缩率通常略低一些。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="1-2-常见剪枝方法"><a href="#1-2-常见剪枝方法" class="headerlink" title="1.2 常见剪枝方法"></a>1.2 常见剪枝方法</h3><ol>
<li><p><strong>基于权重大小的剪枝（Magnitude-based Pruning）</strong></p>
<ul>
<li><p><strong>思想</strong>：假设绝对值较小的参数对网络输出影响有限，可以将它们置零。</p>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li><strong>训练&#x2F;微调阶段</strong>：先获得一个较好的全模型权重（如在 ImageNet、COCO 等数据集预训练）。</li>
<li><strong>剪枝阶段</strong>：对指定层（或所有卷积层、全连接层）的权重按绝对值排序，剔除前 p% 或小于阈值 ε 的权重。</li>
<li><strong>稀疏化&#x2F;稀释</strong>：将被剪枝的权重置为 0，但保留原始张量尺寸。</li>
<li><strong>再训练（Fine-tune）</strong>：对剪枝后网络进行若干轮微调，让剩余权重重新协调、收敛，以尽可能恢复精度。</li>
</ol>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>实现简单，适用范围广；</li>
</ul>
</li>
<li>− 不同层的敏感度不同，单纯按全局阈值剪枝容易导致关键层过度剪切，需要对各层单独设定剪枝比例或阈值。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>基于BatchNorm gamma 的剪枝（BN Gamma Pruning）</strong></p>
<ul>
<li><p><strong>思想</strong>：在卷积层后面通常会接一个 BatchNorm 层，其中的 γ（scale）参数越小，说明该通道对特征图输出影响越小，可以直接删掉对应通道。</p>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>在网络中加入一个“稀疏化正则项”（比如 L1-loss）约束所有 BN 的 γ，使得不重要的 γ → 0。</li>
<li>训练过程中，γ 较小的通道被视作可剪枝目标。</li>
<li>根据预设的剪枝率（如“删去 γ 排名前 20% 的通道”），将相应的卷积通道和 BN 通道一并剔除。</li>
<li>剪枝后微调。同样需要对剩余网络做 Fine-tune 恢复精度。</li>
</ol>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>相对直接判断通道重要性，剪枝后的网络结构依然规则；</li>
</ul>
</li>
<li><ul>
<li>对剪枝前的原始网络只需小幅修改，可在训练时同时进行稀疏正则化；</li>
</ul>
</li>
<li>− 需要额外引入正则化超参数，并且不同层对 γ 的数值分布敏感度不同，容易出现某些层剪得过多、某些层剪得过少。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>结构化通道剪枝（Channel Pruning）</strong></p>
<ul>
<li><p><strong>思想</strong>：直接对卷积层的“整条通道”进行去除。通通常有以下几种度量“通道重要性”的策略：</p>
<ul>
<li><strong>L1-norm</strong> 或 <strong>L2-norm</strong>：对每个卷积核（对应一个输出通道）的权重做 L1 或 L2 范数，范数越大，通道越重要；</li>
<li><strong>利用梯度信息</strong>：计算剪掉某个通道后，Loss 变化的近似值；</li>
<li><strong>基于通道输出的敏感度</strong>：统计某个通道在一批数据上的平均激活值，如果激活值始终很小，说明该通道对最终决策贡献有限。</li>
</ul>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>训练好原始网络；</li>
<li>根据度量策略为每个通道打分，并根据剪枝率（如删去 30% 通道）选择候选通道；</li>
<li>删除卷积核 + 对应 BN、ReLU 等后续操作中的通道；</li>
<li>对剪枝后网络做微调，以恢复性能。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>基于低秩分解（Low-rank Factorization）</strong></p>
<ul>
<li><p><strong>思想</strong>：将一个大的卷积核或全连接层，看作一个大矩阵，通过 SVD、PCA、CP 分解等，将其拆解成多个小矩阵的乘积，从而降低参数量和计算量。</p>
</li>
<li><p><strong>示例</strong>：</p>
<ul>
<li>对于一个 $k \times k$ 卷积核，可以先用 $k \times 1$ 的卷积拆一个分支，再接 $1 \times k$ 的卷积，以近似原卷积。</li>
<li>对于全连接层 $W \in \mathbb{R}^{m \times n}$，做 SVD 分解 $ W \approx U_r \Sigma_r V_r^T$，只保留前 r 个奇异值，从而将原本的矩阵乘法 $xW$ 变成 $x V_r \Sigma_r U_r^T$。</li>
</ul>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>在一些情况下，低秩分解能获得不错的加速及参数压缩；</li>
</ul>
</li>
<li>− 需要对每层做额外分解计算，有时会引入额外的重组操作；不同硬件对分解后的小卷积&#x2F;矩阵乘加支持度不同。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>动态剪枝 &#x2F; 自适应剪枝（Dynamic Pruning）</strong></p>
<ul>
<li><p><strong>思想</strong>：在推理时动态决定哪些通道&#x2F;连接需要计算、哪些可以跳过，从而在不同样本或不同部署环境下，自动调整计算量。</p>
</li>
<li><p><strong>示例</strong>：</p>
<ul>
<li><strong>Gater Network</strong>：用一个轻量级的“决策网络”预测主干网络中哪些通道当前样本需要激活，其他直接跳过；</li>
<li><strong>Early Exit &#x2F; Branchy Net</strong>：在网络中间加入若干分支分类头，当浅层已经能满足高置信度判定时，就提前退出，无需走完整个网络。</li>
</ul>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>相比静态剪枝，更加灵活，能够在简单样本上大幅加速；</li>
</ul>
</li>
<li>− 需要引入额外的控制网络或分支头，增加了设计和调试复杂度。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="二、知识蒸馏（Distillation）"><a href="#二、知识蒸馏（Distillation）" class="headerlink" title="二、知识蒸馏（Distillation）"></a>二、知识蒸馏（Distillation）</h2><h3 id="2-1-蒸馏的基本概念"><a href="#2-1-蒸馏的基本概念" class="headerlink" title="2.1 蒸馏的基本概念"></a>2.1 蒸馏的基本概念</h3><ul>
<li><strong>目的</strong>：通过“将大模型（Teacher）学到的知识迁移到小模型（Student）”，让小模型在参数量、计算资源受限的情况下，尽可能地接近或超越大模型在精度或泛化能力上的表现。</li>
<li><strong>原理</strong>：一般大模型输出除“硬标签”（one-hot label）之外，还有“软标签”（soft probability 分布），它们包含类别之间的相互关系信息（如某张猫图像在被误判为“狐狸”的概率较高，而几率很低的鸟类之间区别更明显）。Student 网络通过对齐 Teacher 的输出分布（Logits 或概率），能够快速学习到更丰富的类内／类间相似性。</li>
</ul>
<h3 id="2-2-经典蒸馏方法"><a href="#2-2-经典蒸馏方法" class="headerlink" title="2.2 经典蒸馏方法"></a>2.2 经典蒸馏方法</h3><ol>
<li><p><strong>Hinton 等人提出的软标签蒸馏（Soft Target Distillation）</strong></p>
<ul>
<li><p><strong>核心损失</strong>：</p>
<p>$$<br>  \mathcal{L} &#x3D; (1 - \alpha) \cdot \mathcal{L}_\text{CE}(y_\text{hard}, p_\text{student}) + \alpha \cdot T^2 , \mathcal{L}_\text{KL}\bigl(\sigma(\tfrac{z_\text{teacher}}{T}),, \sigma(\tfrac{z_\text{student}}{T})\bigr)<br>$$</p>
<ul>
<li>$\mathcal{L}_\text{CE}$：通常是对 Student 的输出与真实硬标签 $y_\text{hard}$ 做交叉熵损失。</li>
<li>$\mathcal{L}_\text{KL}$：KL 散度，用来度量 Teacher 与 Student 在“软概率”上的分布差异。</li>
<li>$T$：temperature（温度系数），控制 softmax 输出的平滑程度；较大 T 值会让概率分布更平滑、信息更丰富；</li>
<li>$\alpha$：权重系数，控制硬标签损失与软标签（Teacher 指导）损失的平衡。</li>
</ul>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>先训练得到一个性能较好的 Teacher 模型；</li>
<li>在 Student 训练阶段，除了用交叉熵拟合硬标签，还需要再用 KL 散度拟合 Teacher 在同一批样本下输出的高温度 softmax 概率；</li>
<li>最终网络参数在双重监督下收敛。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>特征层对齐蒸馏（Feature-based Distillation）</strong></p>
<ul>
<li><p><strong>思想</strong>：不仅对齐最后一层输出概率，还让 Student 去“模仿” Teacher 中间某些层的特征图（feature map）。</p>
</li>
<li><p><strong>常见做法</strong>：</p>
<ul>
<li><strong>FitNet</strong>：对齐某一中间层的 feature map（如 ResNet Block 某一层的输出），通过 $L_2$ 损失让 Student 学到 Teacher 的中间表征。</li>
<li><strong>Attention Transfer</strong>：先把 Teacher 某层特征图在通道维度上做一定方式的“加权”或“平均”，得到一个“注意力图（attention map）”，再让 Student 去拟合这张注意力图。</li>
<li><strong>Relation Distillation</strong>：不只是对齐单个通道的特征，而是让 Student 学到 Teacher 内部不同位置（像素或通道）之间的关系矩阵（如 Gram Matrix）。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>自蒸馏 &#x2F; 跨层蒸馏（Self&#x2F;Layer-wise Distillation）</strong></p>
<ul>
<li><p><strong>思想</strong>：将同一个网络的深层当作 Teacher，把浅层当作 Student，或模型内部不同深度之间互相学习。</p>
</li>
<li><p><strong>示例</strong>：</p>
<ul>
<li><strong>Deeply-Supervised Nets</strong>：在每个中间层末端附加一个分类头，让浅层在监督信号下也输出预测并与深层联合优化；</li>
<li>**ONE (-online distillation)**：训练多个不同宽度的同一架构网络，让它们互相对齐、互相蒸馏。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>生成式蒸馏（Generative Distillation）</strong></p>
<ul>
<li><strong>思想</strong>：用生成器（GAN、Variational Autoencoder 等）模拟 Teacher 模型的“输出分布”，让 Student 直接从“合成数据”上学习，大幅提高数据利用率，尤其是当真实标签稀缺时。</li>
<li><strong>流程</strong>：Generator 生成“伪样本”或“伪特征”，然后让 Teacher 给出“伪标签”，Student 再对齐这些伪标签。</li>
</ul>
</li>
</ol>
<h3 id="2-3-蒸馏的优缺点与注意点"><a href="#2-3-蒸馏的优缺点与注意点" class="headerlink" title="2.3 蒸馏的优缺点与注意点"></a>2.3 蒸馏的优缺点与注意点</h3><ul>
<li><p><strong>优势</strong>：</p>
<ol>
<li><strong>轻量化同时保留精度</strong>：在大模型蒸馏指导下，小模型往往能获得比单纯训练更高的精度；</li>
<li><strong>灵活性强</strong>：可对齐输出层，也可对齐中间特征，能够针对不同场景设计不同蒸馏策略；</li>
<li><strong>可结合其他方法</strong>：蒸馏可以和剪枝、量化等其他压缩手段联合使用，进一步提升性能。</li>
</ol>
</li>
<li><p><strong>局限与注意事项</strong>：</p>
<ol>
<li><strong>Teacher 预训练成本高</strong>：要先得到一个足够强的 Teacher，通常需要更多计算资源；</li>
<li><strong>蒸馏超参数调节较多</strong>：例如温度 $T$、权重系数 $\alpha$、选择对齐哪一层，以及损失函数权重分配，都需要经验和实验调优；</li>
<li><strong>小模型容量有限</strong>：即使有蒸馏指导，如果小模型本身结构设计不合理（过于简单或与任务不匹配），也很难提升到理想精度。</li>
</ol>
</li>
</ul>
<hr>
<h2 id="三、模型部署与加速"><a href="#三、模型部署与加速" class="headerlink" title="三、模型部署与加速"></a>三、模型部署与加速</h2><p>在剪枝和蒸馏之后，往往还需要针对目标硬件做针对性优化，以实现实用级别的高吞吐或低延迟。这部分主要分为“模型导出与转换”、“量化加速”、“推理引擎与框架优化”以及“硬件部署策略”四个小节。</p>
<h3 id="3-1-模型导出与转换"><a href="#3-1-模型导出与转换" class="headerlink" title="3.1 模型导出与转换"></a>3.1 模型导出与转换</h3><ol>
<li><p><strong>PyTorch → TorchScript</strong></p>
<ul>
<li><p><strong>方式</strong>：调用 <code>torch.jit.trace</code> 或 <code>torch.jit.script</code> 将动态图模型转换为静态计算图（TorchScript）。</p>
</li>
<li><p><strong>优点</strong>：</p>
<ul>
<li>方便在无 Python 运行时的环境里部署；</li>
<li>支持进一步调用 C++ API（LibTorch）进行嵌入式应用；</li>
</ul>
</li>
<li><p><strong>注意</strong>：需要保证模型中的自定义算子可被 TorchScript 支持，否则需要手动实现对应的 <code>torch::autograd::Function</code>。</p>
</li>
</ul>
</li>
<li><p><strong>PyTorch → ONNX（Open Neural Network Exchange）</strong></p>
<ul>
<li><p><strong>方式</strong>：使用 <code>torch.onnx.export</code> 导出 .onnx 文件。</p>
</li>
<li><p><strong>优点</strong>：</p>
<ul>
<li>ONNX 是广泛接受的中间格式，可被多种推理引擎（TensorRT、ONNX Runtime、OpenVINO、TVM 等）加载；</li>
<li>可以借助 ONNX Optimizer 对图做剪枝、常量折叠等简单优化。</li>
</ul>
</li>
<li><p><strong>注意事项</strong>：</p>
<ul>
<li>ONNX 导出时要指定 <code>opset_version</code>（一般选 11~16 之间）；</li>
<li>如果模型中有不支持的自定义操作，需要手动注册或将其拆分为基础算子；</li>
<li>注意输入动态维度（如 batch_size、图片长宽）在 ONNX 中的声明。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>PyTorch → TensorFlow &#x2F; TFLite</strong></p>
<ul>
<li><strong>方式</strong>：目前多借助中间库，比如先导出 ONNX，再用 <code>onnx-tensorflow</code> 转为 TensorFlow SavedModel，再使用 TensorFlow Lite Converter 转为 .tflite。</li>
<li><strong>场景</strong>：需要在 Android、iOS、嵌入式 MCU（或 Coral）上部署时，会用到 TFLite。</li>
</ul>
</li>
</ol>
<h3 id="3-2-量化加速（Quantization）"><a href="#3-2-量化加速（Quantization）" class="headerlink" title="3.2 量化加速（Quantization）"></a>3.2 量化加速（Quantization）</h3><p>量化是将网络中的浮点数（FP32、FP16）映射为更低位宽（INT8、INT4、甚至二值）的过程，从而显著减少计算量和内存占用。常见方案有：</p>
<ol>
<li><p><strong>后训练量化（Post-Training Quantization, PTQ）</strong></p>
<ul>
<li><p><strong>原理</strong>：在模型训练完成后，用少量校准数据（Calibration Dataset）收集各层激活分布和权重分布，然后按一定比例映射到 INT8 范围（如 $[-128,127]$）。</p>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>导出静态图（TorchScript、ONNX、TensorFlow SavedModel）；</li>
<li>使用工具（如 PyTorch Quantization API、ONNX Runtime Quantization、TensorFlow Lite Converter）对图做量化；</li>
<li>通过少量样本推理时依次采集动态范围（min、max），生成量化参数；</li>
<li>最终获得一个可用 INT8 推理的模型。</li>
</ol>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>快速、无需再训练；</li>
</ul>
</li>
<li>− 精度损失相比量化感知训练要大一些，尤其在目标检测或语义分割等任务中。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>量化感知训练（Quantization-Aware Training, QAT）</strong></p>
<ul>
<li><p><strong>原理</strong>：在训练时模拟量化误差（在正向传播过程中对权重和激活做“伪量化”），让网络适应量化带来的数值改变。</p>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>在训练脚本中插入量化伪操作（Fake Quant），对权重和激活分别做量化&#x2F;反量化；</li>
<li>在保留梯度计算的同时，让网络对量化误差进行优化，使得最终浮点训练权重“更适合”量化后的整数网络；</li>
<li>训练结束后，将量化伪操作替换为真量化，导出可直接执行 INT8 的推理图。</li>
</ol>
</li>
<li><p><strong>优缺点</strong>：</p>
<ul>
<li><ul>
<li>能够大幅缩小 FP32→INT8 带来的精度损失；</li>
</ul>
</li>
<li>− 需要用比 PTQ 更多的计算资源，再训练时间长；</li>
<li>− 需要对脚本做量化标记，开发成本与调试成本较高。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>其他量化形式</strong></p>
<ul>
<li><strong>混合精度（Mixed-Precision）</strong>：在保持精度的同时，将部分计算（如矩阵乘）用 FP16 或 BF16（Brain Floating Point 16）执行，利用 NVIDIA Tensor Core、自研 NPU 等硬件加速。</li>
<li><strong>极低位宽量化（Lower-bit Quantization）</strong>：如 INT4、二值网络（Binary Neural Networks，BNN）、三值网络（Ternary Neural Networks）。它们进一步压缩模型，但往往精度损失更大，使用场景主要局限于极端算力受限设备。</li>
</ul>
</li>
</ol>
<h3 id="3-3-推理引擎与框架优化"><a href="#3-3-推理引擎与框架优化" class="headerlink" title="3.3 推理引擎与框架优化"></a>3.3 推理引擎与框架优化</h3><ol>
<li><p><strong>TensorRT（NVIDIA）</strong></p>
<ul>
<li><p><strong>支持</strong>：从 ONNX &#x2F; TensorFlow &#x2F; PyTorch（torch2trt） 转换来的模型。</p>
</li>
<li><p><strong>主要功能</strong>：图优化（层融合、常量折叠）、INT8 模式、FP16 模式、Tensor Core 加速、序列化引擎。</p>
</li>
<li><p><strong>常见流程</strong>：</p>
<ol>
<li>导出或转换为 ONNX；</li>
<li>用 <code>trtexec</code> 或 C++ API &#x2F; Python API 生成精度模式（FP32&#x2F;FP16&#x2F;INT8）对应的 Engine；</li>
<li>在部署环境中加载序列化的 Engine，进行高性能推理。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>ONNX Runtime（微软）</strong></p>
<ul>
<li><p><strong>支持</strong>：直接加载 .onnx 模型。</p>
</li>
<li><p><strong>特点</strong>：</p>
<ul>
<li>跨平台（Windows、Linux、ARM、x86 等）；</li>
<li>支持多种执行器（CUDA、TensorRT、MKL-DNN、OpenVINO、NNAPI、CoreML、XNNPACK）。</li>
</ul>
</li>
<li><p><strong>使用步骤</strong>：</p>
<ol>
<li>在 Python &#x2F; C++ 中创建 <code>InferenceSession(&quot;model.onnx&quot;)</code>；</li>
<li>选择合适的执行器（定义 Execution Provider，如 “CUDAExecutionProvider”、“CPUExecutionProvider”）。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>OpenVINO（Intel）</strong></p>
<ul>
<li><p><strong>支持</strong>：将模型（ONNX、TensorFlow、Caffe、PyTorch）转换为 IR（Intermediate Representation，包含 XML + BIN 文件）。</p>
</li>
<li><p><strong>特点</strong>：对 Intel CPU &#x2F; iGPU &#x2F; VPU（Movidius）做了大量图优化和算子融合，尤其擅长在 CPU 上做 INT8 推理。</p>
</li>
<li><p><strong>流程</strong>：</p>
<ol>
<li>使用 Model Optimizer 导出 IR；</li>
<li>在推理时用 Inference Engine API 加载 IR 并执行。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>TVM &#x2F; Apache NNVM &#x2F; XLA &#x2F; TFLite GPU Delegate</strong></p>
<ul>
<li><p><strong>概念</strong>：编译器式深度学习推理框架，会将模型图分解到底层计算图、对算子做融合、针对不同硬件生成高效本地代码。</p>
</li>
<li><p><strong>适用场景</strong>：</p>
<ul>
<li>开发专门针对 ARM 或自研 ASIC 的推理包；</li>
<li>需要对特定网络结构做极致剪裁和融合的轻量化部署。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Zero-Copy Inference &#x2F; Batch 编排</strong></p>
<ul>
<li><p><strong>思想</strong>：在数据预处理、拷贝、推理、后处理各阶段做充分流水线并行，让 CPU 与 GPU&#x2F;加速卡极少等待。</p>
</li>
<li><p><strong>示例</strong>：</p>
<ul>
<li>使用 CUDA Pinned Memory (页锁定内存) 在 Host&#x2F;GPU 之间做 CUDA Zero-Copy；</li>
<li>在多线程流程中预先加载 Batch，GPU 一口气推理多个输入；</li>
<li>推理与后处理异步并行，GPU 推理结果由专门的线程或进程做解码与 NMS。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="3-4-部署时的硬件与工程考量"><a href="#3-4-部署时的硬件与工程考量" class="headerlink" title="3.4 部署时的硬件与工程考量"></a>3.4 部署时的硬件与工程考量</h3><ol>
<li><p><strong>目标设备类型</strong></p>
<ul>
<li><p><strong>云端 GPU &#x2F; 多卡服务器</strong>：重点关注单 → 多 GPU 同步&#x2F;异步推理、CUDA Graph、模型并行&#x2F;数据并行调度。</p>
</li>
<li><p><strong>边缘 GPU（如 NVIDIA Jetson 系列）</strong>：需要使用 TensorRT、JetPack SDK、TensorRT 加速 INT8&#x2F;FP16。</p>
</li>
<li><p><strong>手机端（Android &#x2F; iOS）</strong>：</p>
<ul>
<li>Android：一般使用 TFLite OR Pytorch Mobile OR NNAPI；</li>
<li>iOS：优先使用 CoreML OR MPS（Metal Performance Shaders）。</li>
</ul>
</li>
<li><p><strong>嵌入式板卡 &#x2F; NPU &#x2F; FPGA</strong>：对模型大小、算子支持、内存带宽要求极高，常用量化（INT8）+ TVM &#x2F; Vitis-AI（Xilinx FPGA）、OpenVINO（Movidius VPU）等工具链。</p>
</li>
</ul>
</li>
<li><p><strong>延迟 vs. 吞吐 vs. 功耗</strong></p>
<ul>
<li><p>如果追求单帧最小延迟：</p>
<ul>
<li>建议单张卡做“零拷贝”模式，Batch Size&#x3D;1，FP16&#x2F;INT8，开启图优化；</li>
</ul>
</li>
<li><p>如果追求最大吞吐量：</p>
<ul>
<li>可以做 Batch 推理，开启多流多线程（CUDA Graph、TensorRT 多流），必要时做多卡并行；</li>
</ul>
</li>
<li><p>如果部署在电池供电的设备：</p>
<ul>
<li>必须做量化（最少 FP16，最好 INT8），同时注意关闭不必要的算子、尽量减少内存访问，或者选择轻量级网络架构（MobileNet、ShuffleNet 等）。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>A&#x2F;B 测试与灰度验证</strong></p>
<ul>
<li>在部署到线上前，最好先做 A&#x2F;B 测试，对比“压缩前模型”与“压缩后模型”在真实场景下的召回率、误检率、延迟分布等指标。</li>
<li>如若模型表现出现明显退化，则需回到剪枝&#x2F;蒸馏&#x2F;量化阶段做进一步调优。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="四、常见流程范例"><a href="#四、常见流程范例" class="headerlink" title="四、常见流程范例"></a>四、常见流程范例</h2><p>以下给出一种在目标检测（如 YOLOv8）场景下，从原始模型到最终部署的典型流水线范例，供参考：</p>
<ol>
<li><p><strong>原始训练</strong></p>
<ul>
<li>用 PyTorch+Ultralytics YOLOv8，加载 ImageNet 预训练权重，训练得到 COCO 精度的基准模型（如 mAP&#x3D;50%）。</li>
</ul>
</li>
<li><p><strong>剪枝 + 微调</strong></p>
<ul>
<li>选择结构化剪枝（基于 BN γ）或通道剪枝，对重要性较低的通道进行逐层剪掉，目标剪去 30% 计算量；</li>
<li>剪枝后模型在小规模数据集上微调 50–100 epoch 以恢复至少 98% 的基准 mAP。</li>
</ul>
</li>
<li><p><strong>知识蒸馏</strong></p>
<ul>
<li>用剪枝前性能更高的 Teacher（原始 YOLOv8l）指导剪枝后 Student（YOLOv8s）：在学生端加入蒸馏损失（soft-label + L2 中间特征），恢复或超越剪枝后模型在小数据集上的性能。</li>
</ul>
</li>
<li><p><strong>量化感知训练（QAT）</strong></p>
<ul>
<li>在剪枝+蒸馏之后，利用 PyTorch 的 QAT API，给剪枝+蒸馏后的模型插入 FakeQuant 模块，训练若干轮，让模型适应 INT8 量化；</li>
<li>训练结束后导出 TorchScript INT8 模型。</li>
</ul>
</li>
<li><p><strong>导出与转换</strong></p>
<ul>
<li>将 QAT 后的 TorchScript 模型导出为 ONNX；</li>
<li>使用 TensorRT 将 ONNX 转换成 TF Engine，并生成 FP16&#x2F;INT8 引擎文件。</li>
</ul>
</li>
<li><p><strong>部署验证</strong></p>
<ul>
<li><p>在目标硬件（如 Jetson Xavier、RTX 2080Ti）上分别测试：</p>
<ul>
<li>FP32 – mAP、延迟；</li>
<li>FP16 – mAP、延迟；</li>
<li>INT8 – mAP、延迟；</li>
</ul>
</li>
<li><p>在机器人平台或移动 App 中做 A&#x2F;B 对比测试，确保满足线上指标要求。</p>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><ol>
<li><strong>剪枝</strong> 主要从“静态图层”层面减少冗余参数，通过权重稀疏化或结构化通道删除，实现模型轻量化，但需结合微调恢复精度。</li>
<li><strong>知识蒸馏</strong> 利用大模型（Teacher）的“软标签”与“中间特征”对小模型（Student）进行双重监督，使小模型在有限参数下尽可能接近大模型表现。</li>
<li><strong>加速与部署</strong> 包括“量化（PTQ&#x2F;QAT）”、“推理引擎（TensorRT、ONNX Runtime、OpenVINO等）”和“硬件平台选择”三方面，目的是在目标环境中同时兼顾精度、延迟、吞吐与功耗。</li>
<li><strong>整体思路</strong>：往往需要将上述技术<strong>串联起来</strong>，先做适度剪枝→用蒸馏恢复精度→做量化训练→导出为便于部署的中间格式→在特定硬件上做进一步图优化与流水线并行，才能最终获得高效、低延迟、可商用的模型部署方案。</li>
</ol>
<p>在实际项目中，具体使用哪些技术、先后顺序如何安排，需要根据数据规模、算力预算、延迟要求、目标硬件特性等多方面综合评估并做大量实验验证。以上内容可作为常见思路与方法的全面概览，后续可结合具体场景进行更精细的设计与调优。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>感谢老板支持！敬礼(^^ゞ</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="zhang junyi WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="zhang junyi Alipay">
        <p>Alipay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI%E9%83%A8%E7%BD%B2/" rel="tag"># AI部署</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/06/04/notebook/DeepLearning/2025-06-04--%E5%A6%82%E4%BD%95%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0YOLO%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" rel="prev" title="如何深入学习YOLO网络结构">
      <i class="fa fa-chevron-left"></i> 如何深入学习YOLO网络结构
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/06/05/notebook/OpenCV/opencv_3_%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/2025-06-05--%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B005/" rel="next" title="常用函数">
      常用函数 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%89%AA%E6%9E%9D%EF%BC%88Pruning%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">一、剪枝（Pruning）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E5%89%AA%E6%9E%9D%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 剪枝的基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E5%B8%B8%E8%A7%81%E5%89%AA%E6%9E%9D%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 常见剪枝方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%EF%BC%88Distillation%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">二、知识蒸馏（Distillation）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E8%92%B8%E9%A6%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 蒸馏的基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E7%BB%8F%E5%85%B8%E8%92%B8%E9%A6%8F%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 经典蒸馏方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E8%92%B8%E9%A6%8F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E4%B8%8E%E6%B3%A8%E6%84%8F%E7%82%B9"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 蒸馏的优缺点与注意点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8A%A0%E9%80%9F"><span class="nav-number">4.</span> <span class="nav-text">三、模型部署与加速</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA%E4%B8%8E%E8%BD%AC%E6%8D%A2"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 模型导出与转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F%EF%BC%88Quantization%EF%BC%89"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 量化加速（Quantization）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E4%B8%8E%E6%A1%86%E6%9E%B6%E4%BC%98%E5%8C%96"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 推理引擎与框架优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-%E9%83%A8%E7%BD%B2%E6%97%B6%E7%9A%84%E7%A1%AC%E4%BB%B6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E8%80%83%E9%87%8F"><span class="nav-number">4.4.</span> <span class="nav-text">3.4 部署时的硬件与工程考量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%B8%B8%E8%A7%81%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B"><span class="nav-number">5.</span> <span class="nav-text">四、常见流程范例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93"><span class="nav-number">6.</span> <span class="nav-text">五、总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhang junyi</p>
  <div class="site-description" itemprop="description">工作学习笔记</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">686</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">54</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">99</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/junyiha" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;junyiha" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/zhangjunyiha" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;zhangjunyiha" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhang junyi</span>
</div>

<!--
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>
-->

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
